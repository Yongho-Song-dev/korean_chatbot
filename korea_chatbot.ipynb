{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한국어로하는 문장을 입력하면 그에 따른 답변을 출력하는 chatbot 프로젝트 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from Korpora import Korpora # 한국어 chatbot 말뭉치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇의 병렬 데이터 받아오기\n",
    "\n",
    "-  '**korean_chatbot_data**': 'songys@github 님이 만드신 챗봇 문답 데이터'를 사용하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kcbert': 'beomi@github 님이 만드신 KcBERT 학습데이터',\n",
       " 'korean_chatbot_data': 'songys@github 님이 만드신 챗봇 문답 데이터',\n",
       " 'korean_hate_speech': '{inmoonlight,warnikchow,beomi}@github 님이 만드신 혐오댓글데이터',\n",
       " 'korean_parallel_koen_news': 'jungyeul@github 님이 만드신 병렬 말뭉치',\n",
       " 'korean_petitions': 'lovit@github 님이 만드신 2017.08 ~ 2019.03 청와대 청원데이터',\n",
       " 'kornli': 'KakaoBrain 에서 제공하는 Natural Language Inference (NLI) 데이터',\n",
       " 'korsts': 'KakaoBrain 에서 제공하는 Semantic Textual Similarity (STS) 데이터',\n",
       " 'kowikitext': 'lovit@github 님이 만드신 wikitext 형식의 한국어 위키피디아 데이터',\n",
       " 'namuwikitext': 'lovit@github 님이 만드신 wikitext 형식의 나무위키 데이터',\n",
       " 'naver_changwon_ner': '네이버 + 창원대 NER shared task data',\n",
       " 'nsmc': 'e9t@github 님이 만드신 Naver sentiment movie corpus v1.0',\n",
       " 'question_pair': 'songys@github 님이 만드신 질문쌍(Paired Question v.2)',\n",
       " 'modu_news': '국립국어원에서 만든 모두의 말뭉치: 뉴스 말뭉치',\n",
       " 'modu_messenger': '국립국어원에서 만든 모두의 말뭉치: 메신저 말뭉치',\n",
       " 'modu_mp': '국립국어원에서 만든 모두의 말뭉치: 형태 분석 말뭉치',\n",
       " 'modu_ne': '국립국어원에서 만든 모두의 말뭉치: 개체명 분석 말뭉치',\n",
       " 'modu_spoken': '국립국어원에서 만든 모두의 말뭉치: 구어 말뭉치',\n",
       " 'modu_web': '국립국어원에서 만든 모두의 말뭉치: 웹 말뭉치',\n",
       " 'modu_written': '국립국어원에서 만든 모두의 말뭉치: 문어 말뭉치',\n",
       " 'open_subtitles': 'Open parallel corpus (OPUS) 에서 제공하는 영화 자막 번역 병렬 말뭉치',\n",
       " 'aihub_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어 + 대화 + 뉴스 + 한국문화 + 조례 + 지자체웹사이트)',\n",
       " 'aihub_spoken_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어)',\n",
       " 'aihub_conversation_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (대화)',\n",
       " 'aihub_news_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (뉴스)',\n",
       " 'aihub_korean_culture_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (한국문화)',\n",
       " 'aihub_decree_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (조례)',\n",
       " 'aihub_government_website_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (지자체웹사이트)'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Korpora.corpus_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Korpora] Corpus `korean_chatbot_data` is already installed at /home/ssac27/Korpora/korean_chatbot_data/ChatbotData.csv\n"
     ]
    }
   ],
   "source": [
    "Korpora.fetch('korean_chatbot_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join(os.getenv('HOME'), 'Korpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(root_path +'/korean_chatbot_data/ChatbotData.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label 데이터는 불필요하니 제거하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "0                       12시 땡!                하루가 또 가네요.\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.\n",
       "...                        ...                       ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.\n",
       "\n",
       "[11823 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['label'], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         12시 땡!\n",
       "1                    1지망 학교 떨어졌어\n",
       "2                   3박4일 놀러가고 싶다\n",
       "3                3박4일 정도 놀러가고 싶다\n",
       "4                        PPL 심하네\n",
       "                  ...           \n",
       "11818             훔쳐보는 것도 눈치 보임.\n",
       "11819             훔쳐보는 것도 눈치 보임.\n",
       "11820                흑기사 해주는 짝남.\n",
       "11821    힘든 연애 좋은 연애라는게 무슨 차이일까?\n",
       "11822                 힘들어서 결혼할까봐\n",
       "Name: Q, Length: 11823, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = data['Q']\n",
    "answers = data['A']\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      하루가 또 가네요.\n",
       "1                       위로해 드립니다.\n",
       "2                     여행은 언제나 좋죠.\n",
       "3                     여행은 언제나 좋죠.\n",
       "4                      눈살이 찌푸려지죠.\n",
       "                   ...           \n",
       "11818          티가 나니까 눈치가 보이는 거죠!\n",
       "11819               훔쳐보는 거 티나나봐요.\n",
       "11820                      설렜겠어요.\n",
       "11821    잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822          도피성 결혼은 하지 않길 바라요.\n",
       "Name: A, Length: 11823, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 중에서 5만 개만 가져오도록 하고 질문과 답변의 쌍의 형태로 데이터셋을 가공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 20000 \n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리하기\n",
    "---\n",
    "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (1-9, ㄱ-ㅎ, 가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^1-9ㄱ-ㅎ가-힣?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 로드하는 동시에 전처리 함수를 호출하여 질문과 답변의 쌍을 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "    id2line = {}\n",
    "    inputs, outputs= [], []\n",
    "    \n",
    "    for Q, A in zip(questions, answers):\n",
    "            # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "        inputs.append(preprocess_sentence(Q))\n",
    "        outputs.append(preprocess_sentence(A))\n",
    "\n",
    "        if len(inputs) >= MAX_SAMPLES:\n",
    "            return inputs, outputs\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 샘플 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문과 답변은 병렬적으로 구성되는 데이터셋이므로 두 샘플 수는 정확하게 일치해야 합니다.\n",
    "\n",
    "둘 다 11823 개의 샘플이 저장되었습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q :  12시 땡 !     A :  하루가 또 가네요 .\n",
      "Q :  1지망 학교 떨어졌어     A :  위로해 드립니다 .\n",
      "Q :  3박4일 놀러가고 싶다     A :  여행은 언제나 좋죠 .\n",
      "Q :  3박4일 정도 놀러가고 싶다     A :  여행은 언제나 좋죠 .\n",
      "Q :  심하네     A :  눈살이 찌푸려지죠 .\n",
      "Q :  카드 망가졌어     A :  다시 새로 사는 게 마음 편해요 .\n",
      "Q :  카드 안돼     A :  다시 새로 사는 게 마음 편해요 .\n",
      "Q :  맞팔 왜 안하지     A :  잘 모르고 있을 수도 있어요 .\n",
      "Q :  시간낭비인 거 아는데 매일 하는 중     A :  시간을 정하고 해보세요 .\n",
      "Q :  시간낭비인데 자꾸 보게됨     A :  시간을 정하고 해보세요 .\n"
     ]
    }
   ],
   "source": [
    "# 10개의 샘플들을 확인해 보겠습니다.\n",
    "for q,a in zip(questions[:10], answers[:10]):\n",
    "    print(\"Q : \",q , \"    A : \", a )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?나 .과 같은 구두점들이 단어들과 분리되어 단어와 구두점 사이에는 공백이 추가된 것을 확인할 수 있습니다. 이렇게 함으로써 단어를 토크나이징 하는 과정에서 구두점과 붙어있던 단어들을 하나의 단어로 인식하는 것을 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SubwordTextEncoder 사용하기\n",
    "<br>\n",
    "\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 **SubwordTextEncoder**를 그대로 사용해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TensorFlow Datasets **SubwordTextEncoder**를 토크나이저로 사용한다.  단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 **정수로 인코딩**한다.\n",
    "2. 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 **START_TOKEN** 및 **END_TOKEN**을 추가한다.\n",
    "3. 최대 길이 **MAX_LENGTH**인 40을 넘는 문장들은 필터링한다.\n",
    "4. MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 **패딩**한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 단어장(Vocabulary) 만들기\n",
    "---\n",
    "\n",
    "우선 각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장(Vocabulary)을 만들어보겠습니다. 단어장을 만들 때는 질문과 답변 데이터셋을 모두 사용하여 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장 만들기\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성.\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "print(\"단어장 만들기\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 디코더의 문장 생성 과정에서 사용할 '시작 토큰'과 '종료 토큰'에 대해서도 임의로 단어장에 추가하여서 정수를 부여해 줍니다. 이미 생성된 단어장의 번호와 겹치지 않도록 각각 단어장의 크기와 그보다 1이 큰 수를 번호로 부여하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8154]\n",
      "END_TOKEN의 번호 : [8155]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 8,154과 8,155라는 점에서 현재 단어장의 크기가 8,154(0번부터 8,153번)이라는 의미입니다.\n",
    "\n",
    "두 개의 토큰을 추가해 주었기 때문에 단어장의 크기도 +2가 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8156\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### [2] 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)\n",
    "---\n",
    "위에서 **tensorflow_datasets**의 **SubwordTextEncoder**를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, **tokenizer.encode()**로 각 단어를 정수로 변환할 수 있고 또는 **tokenizer.decode()**를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다.\n",
    "\n",
    "예를 들어서 1번째 샘플을 **tokenizer.encode()**의 입력으로 사용해서 변환 결과를 봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 1번째 질문 샘플: [7947, 47, 916, 7930, 995, 1717]\n",
      "정수 인코딩 후의 1번째 답변 샘플: [1829, 5497, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 1번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 1번째 질문 샘플: {}'.format(tokenizer.encode(questions[1])))\n",
    "print('정수 인코딩 후의 1번째 답변 샘플: {}'.format(tokenizer.encode(answers[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_max_len = 24\n",
    "\n",
    "answer_max_len = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어의 길이 별 비율을 확인하고 패딩할 길이를 정해줍니다.  \n",
    "\n",
    "questions의 max 길이가 answer의 max 길이보다 짧지만 같은 길이로 해야하기에 answer의 max 길이로 맞추겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 그 길이 안에 해당하는지 계산하는 함수 \n",
    "def below_threshold_len( max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if (len(s.split()) <= max_len) :\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 24 이하인 샘플의 비율: 1.0\n",
      "전체 샘플 중 길이가 24 이하인 샘플의 비율: 1.0\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(question_max_len, questions)\n",
    "below_threshold_len(answer_max_len, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 24\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 MAX_LENGTH 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 24으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정수 인코딩 과정을 수행하면서 샘플의 길이가 MAX_LENGTH을 넘는 경우는 샘플들을 필터링해서 일부 샘플이 제외되게 만들어서 일부 샘플이 제외되었습니다.  \n",
    "\n",
    "샘플 필터링할 때 토큰 2개를 포함해서 24개 이하여야 합니다.\n",
    "\n",
    "단어장의 크기와 샘플의 개수를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8156\n",
      "필터링 후의 질문 샘플 개수: 11815\n",
      "필터링 후의 답변 샘플 개수: 11815\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] 교사 강요(Teacher Forcing) 사용하기\n",
    "---\n",
    "**tf.data.Dataset API**는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API입니다.\n",
    "\n",
    "이를 적극 사용하기 위해서 질문과 답변의 쌍을 **tf.data.Dataset**의 입력으로 넣어주는 작업을 합니다.\n",
    "\n",
    "\n",
    "질문과 답변의 쌍을 **tf.data.Dataset API**의 입력으로 사용하여 파이프라인을 구성합니다. 이때, 교사 강요를 위해서 **answers[:, :-1]**를 디코더의 입력값, **answers[:, 1:]**를 디코더의 레이블로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = len(answers)\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 구성하기\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현해 봅시다.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 포지셔널 인코딩 레이어\n",
    "\n",
    "같은 단어라도 그 단어가 문장의 몇 번째 어순으로 입력되었는지를 모델에 추가로 알려 주기 위해, 단어의 임베딩 벡터에다가 **위치 정보를 가진 벡터(Positional Encoding)** 값을 더해서 모델의 입력으로 삼는다.  \n",
    "\n",
    "- 같은 단어라고해도 각각 다른 위치에 등장했다는 사실을 모델에 알려주기 위해 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 포지셔널 인코딩 레이어(Positional Encoding Layer) 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행의 크기가 30, 열의 크기가 256인 행렬을 그려봅시다. 이를테면, 최대 문장의 길이가 30이고 워드 임베딩 차원을 256로 하는 모델의 입력 벡터 모양이 이와 같을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(30, 256)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='gray') # cmap='RdBu'\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 256))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  스케일드 닷 프로덕트 어텐션\n",
    "- 단어들 간의 유사도를 구하는 매커니즘을 말합니다.\n",
    "\n",
    " 유사도 값을 스케일링 해주기 위해서 행렬 전체를 특정 값으로 나눠주고, 유사도를 0과 1사이의 값으로 Normalize해주기 위해서 소프트맥스 함수를 사용합니다. 여기까지가 Q와 K의 유사도를 구하는 과정이라고 볼 수 있겠습니다. 여기에 문장 행렬 V와 곱하면 **어텐션 값(Attention Value)**를 얻습니다.\n",
    "\n",
    "### $$ Attention(Q,K,V) = softmax \\left( \\frac {QK^T} {\\sqrt{d_k}} \\right) V $$\n",
    "\n",
    "\n",
    "이 수식은 내적(dot product)을 통해 단어 벡터 간 유사도를 구한 후에, 특정 값을 분모로 나눠주는 방식으로 Q와 K의 유사도를 구하였다고 하여 **스케일드 닷 프로덕트 어텐션(Scaled Dot Product Attention)**이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스케일드 닷 프로덕트 어텐션(Scaled Dot Product Attention) 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    #어텐션 가중치를 계산.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "      # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 병렬로 어텐션 수행하기\n",
    "\n",
    "트랜스포머에서 **num_heads**라는 변수는 기계가 몇 개의 똑똑한 머리를 사용할지, 다시 말해 병렬적으로 몇 개의 어텐션 연산을 수행할지를 결정하는 하이퍼파라미터입니다.\n",
    "\n",
    "\n",
    "**d_model**이 임베딩 차원이라면, 결국 트랜스포머의 초기 입력인 문장 행렬의 크기는 문장의 길이를 행으로, **d_model**은 열의 크기로 가집니다.\n",
    "\n",
    "트랜스포머는 이렇게 입력된 문장 행렬을 **num_heads**의 수만큼 쪼개서 어텐션을 수행하고, 이렇게 얻은 **num_heads**의 개수만큼의 어텐션 값 행렬을 다시 하나로 **concatenate**합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이와 같이 어텐션을 병렬로 수행하는 것을 **멀티 헤드 어텐션**이라고 부릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**멀티 헤드 어텐션**을 구현하면 다음과 같습니다.\n",
    "\n",
    "내부적으로는 **스케일드 닷 프로덕트 어테션 함수**를 호출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 멀티 헤드 어텐션(multi-head attention) 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마스킹\n",
    "**마스킹(Masking)**이란, 특정 값들을 가려서 실제 연산에 방해가 되지 않도록 하는 기법입니다.\n",
    "\n",
    "트랜스포머에서는 어텐션을 위해서 크게 두 가지 마스킹을 사용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩 마스킹(Padding Masking)  \n",
    "---\n",
    "\n",
    "첫 번째 마스킹은 패딩 토큰(Padding token)을 이용한 방법입니다.\n",
    "\n",
    "\n",
    "패딩을 한 문장에서 주어진 숫자 0은 실제 의미가 있는 단어가 아니므로 실제 어텐션 등과 같은 연산에서는 제외할 필요가 있습니다. **패딩 마스킹**은 이를 위해 숫자 0인 위치를 체크합니다.\n",
    "\n",
    "\n",
    "- 패딩 : 정해준 길이보다 짦은 문장의 경우에는 숫자 0을 채워서 전체 문장의 길이를 맞춰주는 자연어 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 함수에 정수 시퀀스를 입력으로 하면, 이 함수는 숫자가 0인 부분을 체크한 벡터를 리턴합니다.\n",
    "\n",
    "두 개의 정수 시퀀스를 입력으로 해보고, 각각 어떤 결과가 나오는지 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 1. 1. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[0, 3, 0, 4, 0], [1, 5, 0, 0, 2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 정수 시퀀스에 대해서 숫자가 0인 위치에서만 1이 나오고 숫자가 0이 아닌 경우에는 0인 벡터를 출력합니다.  \n",
    "\n",
    "이렇게 어텐션 연산시에 **패딩 마스킹**을 참고해서 불필요하게 숫자 0을 참고하지 않을 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)\n",
    "---\n",
    "\n",
    "RNN은 **step**이라는 개념이 존재해서 각 **step**마다 단어가 순서대로 입력으로 들어가는 구조인 반면 트랜스포머의 경우에는 문장 행렬을 만들어 한 번에 행렬 형태로 입력으로 들어간다는 특징이 있습니다. 그리고 이 특징 때문에 추가적인 **마스킹(Masking)**을 필요합니다.\n",
    "\n",
    "트렌스포머의 경우, 전체 문장이 문장 행렬로 들어가기 때문에 위치와 상관없이 모든 단어를 참고해서 다음 단어를 예측할 수 있습니다. 하지만 실제로 원하는 것은 이전 단어들로부터 다음 단어를 예측하는 훈련을 제대로 하는 것입니다.  \n",
    "따라서 이러한 문제를 해결하기 위해 자신보다 다음에 나올 단어를 참고하지 않도록 가리는 기법이 **룩 어헤드 마스킹 기법**입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1,2,3,4,5]의 정수 시퀀스를 입력 해보고 어떤 결과가 나오는지 확인해 보곘습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대각선의 형태로 숫자 1이 채워지는 것을 볼 수 있습니다. 그런데 이 마스킹과 패딩 마스킹은 별개이므로, 이 마스킹을 수행할 때 만약에 숫자 0인 단어가 있다면 이 또한 패딩 해야 합니다. 그래서 **create_look_ahead_mask()** 함수는 내부적으로 앞서 구현한 패딩 마스크 함수도 호출하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 1. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[0, 2, 1, 0, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 부분을 마스킹을 한채로 대각선 형태로 숫자 1이 채워져 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 인코더 설계\n",
    "\n",
    "트랜스포머의 인코더를 설계해 보겠습니다.\n",
    "\n",
    "하나의 인코더 층은 크게 총 2개의 서브 층(sublayer)으로 나누어집니다.\n",
    "바로 **셀프 어텐션**과 **피드 포워드 신경망**입니다. 셀프 어텐션은 **멀티 헤드 어텐션**으로 병렬적으로 이루어집니다.\n",
    "\n",
    "두 개의 서브 층을 가지는 하나의 인코더 층을 구현하는 함수는 다음과 같습니다. 함수 내부적으로 첫 번째 서브 층와 두 번째 서브 층을 구현하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코더 층을 쌓아 인코더 만들기\n",
    "---\n",
    "이렇게 구현한 인코더 층을 **임베딩 층(Embedding layer)**과 **포지셔널 인코딩(Positional Encoding)**을 연결하고, 사용자가 원하는 만큼 인코더 층을 쌓음으로써 트랜스포머의 인코더가 완성됩니다.\n",
    "\n",
    "인코더와 디코더 내부에서는 각 서브층 이후에 훈련을 돕는 **Layer Normalization**이라는 테크닉이 사용되었습니다. 위 그림에서는 **Normalize**라고 표시된 부분에 해당됩니다.\n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 **num_layers** 개수의 인코더 층을 쌓습니다.  논문에서는 총 6개의 인코더 층을 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 디코더 설계\n",
    "\n",
    "디코더는 인코더와 비슷하지만, 인코더보다 조금 더 복잡합니다. 인코더는 두 개의 서브 층으로 구성되지만, 디코더는 세 개의 서브 층으로 구성된다는 점이 다릅니다.\n",
    "\n",
    "\n",
    "인코더의 **셀프 어텐션**과 마찬가지로 디코더의 **셀프 어텐션**, **인코더-디코더 어텐션** 두 개의 어텐션 모두 **스케일드 닷 프로덕트 어텐션**을 **멀티 헤드 어텐션**으로 병렬적으로 수행합니다.\n",
    "\n",
    "디코더의 세 개의 서브 층을 내부적으로 구현한 디코더의 함수는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더 층을 쌓아 디코더 만들기\n",
    "---\n",
    "이렇게 구현한 디코더의 층은 **임베딩 층(Embedding layer)**과 **포지셔널 인코딩(Positional Encoding)**을 연결하고, 사용자가 원하는 만큼 디코더 층을 쌓아 트랜스포머의 디코더가 완성됩니다.\n",
    "\n",
    "인코더와 마찬가지로 **num_layers** 개수의 디코더 층을 쌓습니다. 논문에서는 총 6개의 디코더 층을 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더 층과 디코더 층을 각각 함수로 구현하였습니다.\n",
    "\n",
    "이제 위에서 만들었던 함수들을 가지고 **transformer** 모델을 만들어 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "      # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "      # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 모델 생성\n",
    "---\n",
    "**num_layers**, **d-Model**, **units**는 전부 사용자가 정할 수 있는 하이퍼파라미터값입니다.\n",
    "\n",
    "논문에서 **num_layers**는 6, **d-Model**은 512였지만, 빠르고 원활한 훈련을 위해 여기서는 각 하이퍼파라미터를 논문에서보다는 작은 값을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, None, 256)    4196352     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, None, 256)    5251072     dec_inputs[0][0]                 \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8156)   2096092     decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,543,516\n",
      "Trainable params: 11,543,516\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 손실 함수(Loss function)\n",
    "---\n",
    "레이블인 시퀀스에 패딩이 되어져 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] 커스텀된 학습률(Learning rate)\n",
    "---\n",
    "\n",
    "딥러닝 모델학습 시 learning rate는 매우 중요한 하이퍼파라미터입니다. 최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다. 이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 합니다.\n",
    "\n",
    "논문에 나온 공식을 참고하여 커스텀 학습률 스케줄러를 통한 아담 옵티마이저를 사용합니다. 논문에 나온 공식은 다음과 같습니다.\n",
    "\n",
    "### $$ lrate = d_{model}^{-0.5} \\cdot min(step\\_num^{-0.5}, step\\_num \\cdot warmup\\_steps^{-1.5}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러면 방금 정의한 커스텀 학습률 스케줄링 계획을 시각화해 봅시다. 위에 언급한 수식은 \n",
    "$step\\_num^{−0.5}$\n",
    "에 비례하는 부분과 \n",
    "\n",
    "$step\\_num$\n",
    "에 비례하는 부분 중 작은 쪽을 택하도록 되어 있습니다. 그래서 학습 초기에는 learning_rate가 \n",
    "$step\\_num$\n",
    "에 비례해서 증가하다가 이후로는 감소하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] 모델 컴파일\n",
    "---\n",
    "손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model compile\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"model compile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5] 훈련하기\n",
    "---\n",
    "총 20 에포크를 학습합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 2.4399 - accuracy: 0.0357\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 1.9883 - accuracy: 0.0800\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 1.6995 - accuracy: 0.0855\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 1.5823 - accuracy: 0.0914\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 1.5038 - accuracy: 0.0954\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 1.4238 - accuracy: 0.1002\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 1.3333 - accuracy: 0.1063\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 1.2304 - accuracy: 0.1153\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 1.1191 - accuracy: 0.1270\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 1.0017 - accuracy: 0.1395\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.8823 - accuracy: 0.1542\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.7632 - accuracy: 0.1688\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 0.6516 - accuracy: 0.1834\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.5479 - accuracy: 0.1966\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.4580 - accuracy: 0.2087\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.3817 - accuracy: 0.2199\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.3190 - accuracy: 0.2289\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.2691 - accuracy: 0.2374\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.2292 - accuracy: 0.2436\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.2026 - accuracy: 0.2486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f95d06ade90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 평가하기\n",
    "입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇 테스트하기\n",
    "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.\n",
    "\n",
    "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2. 입력 문장을 토크나이징하고, **START_TOKEN**과 **END_TOKEN**을 추가한다.\n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6. **END_TOKEN**이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.\n",
    "\n",
    "위의 과정을 모두 담은 **decoder_inference()** 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해서 **decoder_inference()** 함수를 호출하여 챗봇의 대답을 얻는 **sentence_generation()** 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕하세요\n",
      "출력 : 안녕하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요 .'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('안녕하세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 외로워\n",
      "출력 : 혼자가 아니에요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'혼자가 아니에요 .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"요즘 외로워\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 잘지내\n",
      "출력 : 잘 지낼 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 지낼 거예요 .'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"요즘 잘지내\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너 왜 그렇게 낯설어\n",
      "출력 : 어흥 ! ! 호랑이보다 무섭나요 ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'어흥 ! ! 호랑이보다 무섭나요 ?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너 왜 그렇게 낯설어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 요즘 심심해\n",
      "출력 : 저도요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도요 .'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"나 요즘 심심해\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 같이 놀래?\n",
      "출력 : 저랑 놀아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저랑 놀아요 .'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"같이 놀래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 고마워\n",
      "출력 : 감사합니다 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'감사합니다 .'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"고마워\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각보다 chatbot이 더 잘 학습되어서 좋은 결과들이 많이 나왔네요.\n",
    "\n",
    "그리고 chatbot에서 사용한 데이터 특성상 위로해 주는 문장이 들어갔을때 더 좋은 답변이 나오네요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "- chatbot 프로젝트를 진행하면서 여러 이론들을 이해하기 어려웠고 잘 될지 감이 안잡혔지만 만족할만한 결과가 나와서 다행이라고 생각이 들었습니다.  그리고 출력 문장을 보면서 실제 있는 휴대폰 어플인 심심이가 생각이 나면서 저랑 대화를 한다는 느낌이 들었습니다.  \n",
    "\n",
    "\n",
    "- 실제론 그저 주어진 Questions에 대해 Answers를 학습한 딥러닝 모델의 불가하지만, 그래도 입력 : \"같이 놀래?\"를 적을때 출력에서 \"저랑 놀아요.\"가 나오자 단순히 계산에 의하여 학습된 장치에 불가하지만 따뜻한 위로를 받는 느낌이 들었습니다.  \n",
    "그래서 이 프로젝트를 하면서 만약 더 정교한 질문도 괜찮은 답변을하는 **chatbot**을 만들 수 있다면, 일상 생활 속에서 외롭거나 힘들때 대화를 해서 위로를 얻을 가능성을 봤습니다.  \n",
    "제가 만든 간단한 모델에서도 저 스스로 어떤 느낌을 얻었으니까요\n",
    "\n",
    "\n",
    "- 모든 사람들이 지금 안좋은 시기를 겪고 있습니다. 연령에 상관없이 모든 사람이 힘든 상활을 겪고 있죠. 이럴때 서로 힘든 사람들끼리 '나 요새 힘들다...  , 너도 그러냐 나도 요새 힘들다 진짜'와 같이 서로 격려해주기 힘든 상황에 이런 **chatbot**이 서로 격려를 해줄 수 있는 하나의 방안이 될 수 있을것 같아서 프로젝트를 하면서도 더 공부하고 싶어졌네요. \n",
    "\n",
    "\n",
    "- 저는 chatbot 기술이 좀 더 서로 격려하고 위로하는 사회를 만드는 하나의 손길과 같은 기술이라고 생각이 듭니다. 그래서 앞으로 chatbot 분야에서 어떤 기술이 나올지 너무 기대가 되네요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
